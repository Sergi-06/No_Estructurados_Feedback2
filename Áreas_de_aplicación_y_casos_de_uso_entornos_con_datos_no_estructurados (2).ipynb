{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX8gZlVyCCbz"
      },
      "source": [
        "# ACTIVIDAD : Redes Convolucionales\n",
        "\n",
        "---\n",
        "\n",
        "En esta actividad, vamos a trabajar con Convolutional Neural Networks para resolver un problema de clasificaci√≥n de im√°genes. En particular, vamos a clasificar im√°genes de personajes los Simpsons.\n",
        "\n",
        "<center><img src=\"https://i.imgur.com/i8zIGqX.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
        "\n",
        "El dataset a utilizar consiste en im√°genes de personajes de la serie extra√≠das directamente de cap√≠tulos de la serie. Este dataset ha sido recopilado por [Alexandre Attia](http://www.alexattia.fr/)\n",
        "Partiendo de los 18 personajes etiquetados, √©stos pueden aparecer en distintas poses, en distintas posiciones de la imagen o con otros personajes en pantalla (si bien el personaje a clasificar siempre aparece en la posici√≥n predominante).\n",
        "\n",
        "El dataset de training puede ser descargado desde aqu√≠:\n",
        "\n",
        "[Training data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219337&authkey=AMzI92bJPx8Sd60) (~500MB)\n",
        "\n",
        "Por otro lado, el dataset de test puede ser descargado de aqu√≠:\n",
        "\n",
        "[Test data](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219341&authkey=ANnjK3Uq1FhuAe8) (~10MB)\n",
        "\n",
        "Antes de empezar la pr√°ctica, se recomienda descargar las im√°genes y echarlas un vistazo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI274F8LQC59"
      },
      "source": [
        "## Carga de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D7tKOZ9BFfki"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sergi.zarzuelo.abel1\\AppData\\Local\\miniconda3\\envs\\no_estr_fed2_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "## Librer√≠as utilizadas\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "import shutil\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFJQpxdsrSKB"
      },
      "source": [
        "Nos descargamos la carpeta de la web de Kaggle:\n",
        "https://www.kaggle.com/datasets/alexattia/the-simpsons-characters-dataset?resource=download&select=simpsons_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xL42LoDCOdd",
        "outputId": "8f87c038-ea2c-4d10-f8e0-6f3d8ab3ba7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\n",
            "Descargado en: C:\\Users\\sergi.zarzuelo.abel1\\.cache\\kagglehub\\datasets\\alexattia\\the-simpsons-characters-dataset\\versions\\4\n",
            "‚ö†Ô∏è Carpeta existente eliminada: ./simpsons_dataset\n",
            "‚úÖ Dataset copiado a: ./simpsons_dataset\n"
          ]
        }
      ],
      "source": [
        "## Descargar dataset\n",
        "path = kagglehub.dataset_download(\"alexattia/the-simpsons-characters-dataset\")\n",
        "print(\"Descargado en:\", path)\n",
        "\n",
        "## Definir rutas\n",
        "source_path = os.path.join(path, \"simpsons_dataset\")\n",
        "target_path = \"./simpsons_dataset\"\n",
        "\n",
        "## Si ya existe, eliminar y copiar de nuevo\n",
        "if os.path.exists(target_path):\n",
        "    shutil.rmtree(target_path)\n",
        "    print(f\"‚ö†Ô∏è Carpeta existente eliminada: {target_path}\")\n",
        "\n",
        "shutil.copytree(source_path, target_path)\n",
        "print(f\"‚úÖ Dataset copiado a: {target_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub7VfNIsst7G"
      },
      "source": [
        "Podemos ver que los personajes est√°n repartidos en carpetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw0apA7ruy1c",
        "outputId": "daa583dd-0188-415b-d9cf-b187e8b65f12"
      },
      "outputs": [],
      "source": [
        "# ## Los personajes se encuentran en carpetas\n",
        "# !ls $path/simpsons_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrRrb_D0MuSI",
        "outputId": "d8f3d525-3624-4215-876d-cd6c460586df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simpsons_dataset               -> 0 im√°genes\n",
            "lionel_hutz                    -> 3 im√°genes\n",
            "disco_stu                      -> 8 im√°genes\n",
            "troy_mcclure                   -> 8 im√°genes\n",
            "miss_hoover                    -> 17 im√°genes\n",
            "fat_tony                       -> 27 im√°genes\n",
            "gil                            -> 27 im√°genes\n",
            "otto_mann                      -> 32 im√°genes\n",
            "sideshow_mel                   -> 40 im√°genes\n",
            "agnes_skinner                  -> 42 im√°genes\n",
            "rainier_wolfcastle             -> 45 im√°genes\n",
            "cletus_spuckler                -> 47 im√°genes\n",
            "snake_jailbird                 -> 55 im√°genes\n",
            "professor_john_frink           -> 65 im√°genes\n",
            "martin_prince                  -> 71 im√°genes\n",
            "patty_bouvier                  -> 72 im√°genes\n",
            "ralph_wiggum                   -> 89 im√°genes\n",
            "carl_carlson                   -> 98 im√°genes\n",
            "selma_bouvier                  -> 103 im√°genes\n",
            "barney_gumble                  -> 106 im√°genes\n",
            "groundskeeper_willie           -> 121 im√°genes\n",
            "maggie_simpson                 -> 128 im√°genes\n",
            "waylon_smithers                -> 181 im√°genes\n",
            "mayor_quimby                   -> 246 im√°genes\n",
            "lenny_leonard                  -> 310 im√°genes\n",
            "nelson_muntz                   -> 358 im√°genes\n",
            "edna_krabappel                 -> 457 im√°genes\n",
            "comic_book_guy                 -> 469 im√°genes\n",
            "kent_brockman                  -> 498 im√°genes\n",
            "apu_nahasapeemapetilon         -> 623 im√°genes\n",
            "sideshow_bob                   -> 877 im√°genes\n",
            "abraham_grampa_simpson         -> 913 im√°genes\n",
            "chief_wiggum                   -> 986 im√°genes\n",
            "milhouse_van_houten            -> 1079 im√°genes\n",
            "charles_montgomery_burns       -> 1193 im√°genes\n",
            "principal_skinner              -> 1194 im√°genes\n",
            "krusty_the_clown               -> 1206 im√°genes\n",
            "marge_simpson                  -> 1291 im√°genes\n",
            "bart_simpson                   -> 1342 im√°genes\n",
            "lisa_simpson                   -> 1354 im√°genes\n",
            "moe_szyslak                    -> 1452 im√°genes\n",
            "ned_flanders                   -> 1454 im√°genes\n",
            "homer_simpson                  -> 2246 im√°genes\n"
          ]
        }
      ],
      "source": [
        "dataset_dir = target_path\n",
        "conteo_imagenes = {}\n",
        "\n",
        "for cls in sorted(os.listdir(dataset_dir)):\n",
        "    cls_path = os.path.join(dataset_dir, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        imagenes = [f for f in os.listdir(cls_path) if f.endswith('.jpg')]\n",
        "        conteo_imagenes[cls] = len(imagenes)\n",
        "\n",
        "## Mostrar resultados ordenados\n",
        "for cls, count in sorted(conteo_imagenes.items(), key=lambda x: x[1]):\n",
        "    print(f\"{cls:30s} -> {count} im√°genes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BmK1qaarpfc"
      },
      "source": [
        "Como Lionel solo tiene tres im√°genes, lo quitamos del entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FJZLHp2_M745"
      },
      "outputs": [],
      "source": [
        "# !rm -r ./simpsons_dataset/lionel_hutz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree(\"./simpsons_dataset/lionel_hutz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrQNXod-sQVJ"
      },
      "source": [
        "Ahora generaremos diferentes carpetas separando los datos de train, test y validaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLrVzEcBK0O_",
        "outputId": "f6e7a428-0e4f-4ffa-b4d7-dd86bc18dd1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Aviso] Clase 'simpsons_dataset' tiene muy pocas im√°genes (0). Se asignan todas a entrenamiento.\n"
          ]
        }
      ],
      "source": [
        "## Definimos los paths\n",
        "ORIGINAL_DATASET_DIR = './simpsons_dataset'\n",
        "BASE_OUTPUT_DIR = './simpsons_split_dataset'\n",
        "\n",
        "## Porcentajes; he optado por generar sets de train, test y validaci√≥n.\n",
        "## Pero pod√©is variar los porcentajes\n",
        "train_pct = 0.7\n",
        "val_pct = 0.15\n",
        "test_pct = 0.15\n",
        "\n",
        "## Crear estructura de carpetas\n",
        "splits = ['train', 'val', 'test']\n",
        "classes = os.listdir(ORIGINAL_DATASET_DIR)\n",
        "classes = [cls for cls in classes if os.path.isdir(os.path.join(ORIGINAL_DATASET_DIR, cls))]\n",
        "\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        os.makedirs(os.path.join(BASE_OUTPUT_DIR, split, cls), exist_ok=True)\n",
        "\n",
        "## Dividir y copiar im√°genes\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(ORIGINAL_DATASET_DIR, cls)\n",
        "    images = [f for f in os.listdir(cls_path) if f.endswith('.jpg')]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    # Asignaci√≥n predeterminada\n",
        "    train, val, test = [], [], []\n",
        "\n",
        "    if len(images) >= 3:\n",
        "        train, temp = train_test_split(images, train_size=train_pct, random_state=42)\n",
        "        val, test = train_test_split(temp, test_size=test_pct / (test_pct + val_pct), random_state=42)\n",
        "    else:\n",
        "        # Si hay muy pocas im√°genes, lo mandamos todo al entrenamiento\n",
        "        train = images\n",
        "        print(f\"[Aviso] Clase '{cls}' tiene muy pocas im√°genes ({len(images)}). Se asignan todas a entrenamiento.\")\n",
        "\n",
        "    for img_list, split in zip([train, val, test], ['train', 'val', 'test']):\n",
        "        for img in img_list:\n",
        "            src = os.path.join(cls_path, img)\n",
        "            dst = os.path.join(BASE_OUTPUT_DIR, split, cls, img)\n",
        "            shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ykLYe16NQji",
        "outputId": "bfc56f30-3d0d-4f96-f04e-3b686f2207da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'abraham_grampa_simpson',\n",
              " 1: 'agnes_skinner',\n",
              " 2: 'apu_nahasapeemapetilon',\n",
              " 3: 'barney_gumble',\n",
              " 4: 'bart_simpson',\n",
              " 5: 'carl_carlson',\n",
              " 6: 'charles_montgomery_burns',\n",
              " 7: 'chief_wiggum',\n",
              " 8: 'cletus_spuckler',\n",
              " 9: 'comic_book_guy',\n",
              " 10: 'disco_stu',\n",
              " 11: 'edna_krabappel',\n",
              " 12: 'fat_tony',\n",
              " 13: 'gil',\n",
              " 14: 'groundskeeper_willie',\n",
              " 15: 'homer_simpson',\n",
              " 16: 'kent_brockman',\n",
              " 17: 'krusty_the_clown',\n",
              " 18: 'lenny_leonard',\n",
              " 19: 'lisa_simpson',\n",
              " 20: 'maggie_simpson',\n",
              " 21: 'marge_simpson',\n",
              " 22: 'martin_prince',\n",
              " 23: 'mayor_quimby',\n",
              " 24: 'milhouse_van_houten',\n",
              " 25: 'miss_hoover',\n",
              " 26: 'moe_szyslak',\n",
              " 27: 'ned_flanders',\n",
              " 28: 'nelson_muntz',\n",
              " 29: 'otto_mann',\n",
              " 30: 'patty_bouvier',\n",
              " 31: 'principal_skinner',\n",
              " 32: 'professor_john_frink',\n",
              " 33: 'rainier_wolfcastle',\n",
              " 34: 'ralph_wiggum',\n",
              " 35: 'selma_bouvier',\n",
              " 36: 'sideshow_bob',\n",
              " 37: 'sideshow_mel',\n",
              " 38: 'simpsons_dataset',\n",
              " 39: 'snake_jailbird',\n",
              " 40: 'troy_mcclure',\n",
              " 41: 'waylon_smithers'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Crear diccionario de mapeo autom√°ticamente\n",
        "MAP_CHARACTERS = {i: cls for i, cls in enumerate(sorted(classes))}\n",
        "MAP_CHARACTERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBbmz9DMhVhc"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "Utilizando Convolutional Neural Networks, entrenar al menos dos clasificadores que sean capaz de reconocer personajes en im√°genes de los Simpsons con una accuracy en el dataset de test de, al menos, **90%**. Redactar un informe analizando varias de las alternativas probadas y los resultados obtenidos.\n",
        "\n",
        "A continuaci√≥n se detallan una serie de aspectos orientativos que podr√≠an ser analizados en vuestro informe (no es necesario tratar todos ellos, pero cu√°nta m√°s informaci√≥n pod√°is aportar mejor a la hora de desarrollar vuestro modelo):\n",
        "\n",
        "*   An√°lisis de los datos a utilizar. ¬øQu√© distribuci√≥n siguen? ¬øEst√°n las clases balanceadas?\n",
        "*   An√°lisis de resultados, obtenci√≥n de m√©tricas de *precision* y *recall* por clase y an√°lisis de qu√© clases obtienen mejores o peores resultados.\n",
        "*   An√°lisis visual de los errores de la red. ¬øQu√© tipo de im√°genes o qu√© personajes dan m√°s problemas a nuestro modelo?\n",
        "*   Comparaci√≥n de modelos CNNs con un modelo de Fully Connected (sin convoluci√≥n) para este problema.\n",
        "*   Utilizaci√≥n de distintas arquitecturas CNNs, comentando aspectos como su profundidad, hiperpar√°metros utilizados, optimizador, uso de t√©cnicas de regularizaci√≥n, *batch normalization*, etc.\n",
        "*   Utilizaci√≥n de *data augmentation*. Esto puede conseguirse con la clase [ImageDataGenerator](https://keras.io/preprocessing/image/#imagedatagenerator-class) de Keras.\n",
        "\n",
        "\n",
        "Notas:\n",
        "* Los datos est√°n en una √∫nica carpeta, por lo que tendr√°s que hacer el split entre train y test\n",
        "* Recuerda partir los datos en training/validation para tener una buena estimaci√≥n de los valores que nuestro modelo tendr√° en los datos de test, as√≠ como comprobar que no estamos cayendo en overfitting. Una posible partici√≥n puede ser 80 / 20.\n",
        "* No es necesario mostrar en el notebook las trazas de entrenamiento de todos los modelos entrenados, si bien una buena idea seria guardar gr√°ficas de esos entrenamientos para el an√°lisis. Sin embargo, **se debe mostrar el entrenamiento completo de al menos los dos mejores modelos obtenidos y la evaluaci√≥n de los datos de test con estos modelos**.\n",
        "* Las im√°genes **no est√°n normalizadas**. Hay que normalizarlas como hemos hecho en trabajos anteriores.\n",
        "* El test set del problema tiene im√°genes un poco m√°s sencillas de identificar, por lo que es posible encontrarse con m√©tricas en el test set bastante mejores que en el training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisis de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta secci√≥n se analizan los datos que se utilizar√°n en el entrenamiento de los modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo 1 (CNN simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta secci√≥n se va a desarrollar un modelo CNN simple. Aunque Keras o TensorFlow pueden ser mas amigables a la hora de programar un modelo, este ser√° desarrollado en PyTorch dado que es m√°s complicado (estamos para aprender) y m√°s utilizado en casos reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\sergi.zarzuelo.abel1\\AppData\\Local\\miniconda3\\envs\\no_estr_fed2_env\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
            "File \u001b[1;32mc:\\Users\\sergi.zarzuelo.abel1\\AppData\\Local\\miniconda3\\envs\\no_estr_fed2_env\\lib\\site-packages\\torch\\__init__.py:132\u001b[0m\n\u001b[0;32m    130\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    131\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\sergi.zarzuelo.abel1\\AppData\\Local\\miniconda3\\envs\\no_estr_fed2_env\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# üìç Rutas a tus carpetas\n",
        "train_dir = \"./simpsons_split_dataset/train\"\n",
        "val_dir = \"./simpsons_split_dataset/val\"\n",
        "test_dir = \"./simpsons_split_dataset/test\"\n",
        "\n",
        "# üîÑ Transformaciones\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# üìÇ Datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform_train)\n",
        "val_dataset   = datasets.ImageFolder(val_dir, transform=transform_val_test)\n",
        "test_dataset  = datasets.ImageFolder(test_dir, transform=transform_val_test)\n",
        "\n",
        "# üßæ Clases\n",
        "print(\"Clases detectadas:\", train_dataset.classes)\n",
        "\n",
        "# üß≥ DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# üëÅ Visualizaci√≥n de im√°genes (opcional)\n",
        "def show_batch(loader, dataset):\n",
        "    images, labels = next(iter(loader))\n",
        "    fig, ax = plt.subplots(4, 8, figsize=(12, 6))\n",
        "    for i in range(32):\n",
        "        img = images[i].permute(1, 2, 0) * 0.5 + 0.5  # desnormaliza\n",
        "        ax[i//8, i%8].imshow(img)\n",
        "        ax[i//8, i%8].axis('off')\n",
        "        ax[i//8, i%8].set_title(dataset.classes[labels[i]])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# (Opcional) Visualiza un batch de entrenamiento\n",
        "show_batch(train_loader, train_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "no_estr_fed2_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
